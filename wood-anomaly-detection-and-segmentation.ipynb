{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Görev Tanımı\n",
        "Bu görevde, verilen ahşap yüzey verileri kullanılarak denetimsiz öğrenme (unsupervised learning) yaklaşımıyla bir anomali tespit modeli geliştirilecektir. Model, ahşap yüzeyinde kusurların veya düzensizliklerin tespit edilmesi için eğitilecektir.\n"
      ],
      "metadata": {
        "id": "B88JmkSORXM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Ön İşleme Adımları ve Veri Hazırlığı\n"
      ],
      "metadata": {
        "id": "6hMrghTkROkk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Google Drive'ı bağla\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Drive'dan veri setine erişim\n",
        "data_path = '/content/drive/MyDrive/wood_dataset/'\n",
        "\n",
        "# train/good klasörüne erişim\n",
        "train_good_path = os.path.join(data_path, 'wood/train/good/')\n",
        "\n",
        "# test/good klasörüne erişim\n",
        "test_good_path = os.path.join(data_path, 'wood/test/good/')\n",
        "\n",
        "# test/defect klasörüne erişim\n",
        "test_defect_path = os.path.join(data_path, 'wood/test/defect/')\n",
        "\n",
        "# ground_truth/defect klasörüne erişim\n",
        "ground_truth_defect_path = os.path.join(data_path, 'wood/ground_truth/defect/')\n",
        "\n",
        "# İşlenmiş resimler için çıkış klasörü\n",
        "output_dir = 'processed_images'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7npICuj8A9BG",
        "outputId": "9d23baeb-a6fc-45b1-cd11-9221602bd6db"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Arka Planı Kaldırma\n"
      ],
      "metadata": {
        "id": "beAnZmQfBFIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def crop_and_clean(image):\n",
        "    # Gri tonlamaya çevir\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Otsu Threshold uygula\n",
        "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Siyah olmayan alanları bul\n",
        "    coords = cv2.findNonZero(thresh)\n",
        "\n",
        "    if coords is not None:\n",
        "        # En küçük dikdörtgeni belirle ve kırp\n",
        "        x, y, w, h = cv2.boundingRect(coords)\n",
        "        cropped_image = image[y:y+h, x:x+w]\n",
        "\n",
        "        # İkinci kontrol\n",
        "        gray_cropped = cv2.cvtColor(cropped_image, cv2.COLOR_BGR2GRAY)\n",
        "        _, clean_thresh = cv2.threshold(gray_cropped, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Yeniden kırp\n",
        "        new_coords = cv2.findNonZero(clean_thresh)\n",
        "        if new_coords is not None:\n",
        "            x2, y2, w2, h2 = cv2.boundingRect(new_coords)\n",
        "            cropped_image = cropped_image[y2:y2+h2, x2:x2+w2]\n",
        "\n",
        "    return cropped_image\n"
      ],
      "metadata": {
        "id": "Yox-t8Bg0QvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Görüntü Normalizasyonu ve Boyutlandırma"
      ],
      "metadata": {
        "id": "oUaM_iASBT8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resize_and_normalize(image, target_size=(256, 256)):\n",
        "    # Boyutlandırma\n",
        "    resized_image = cv2.resize(image, target_size)\n",
        "\n",
        "    # Normalizasyon [0, 1] aralığına\n",
        "    normalized_image = resized_image / 255.0\n",
        "\n",
        "    return normalized_image\n"
      ],
      "metadata": {
        "id": "e99j-mpgBWGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_image(image):\n",
        "    # Kırpma ve temizleme\n",
        "    cropped_image = crop_and_clean(image)\n",
        "\n",
        "    # Boyutlandırma ve normalizasyon\n",
        "    final_image = resize_and_normalize(cropped_image)\n",
        "\n",
        "\n",
        "    return final_image\n"
      ],
      "metadata": {
        "id": "q74zJ1eV7pY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 'train/good' klasöründeki tüm resimleri işleyip kaydetme\n",
        "for filename in os.listdir(train_good_path):\n",
        "    if filename.endswith(('jpg', 'png')):  # Sadece resim dosyaları\n",
        "        img_path = os.path.join(train_good_path, filename)\n",
        "\n",
        "        # Resmi oku\n",
        "        image = cv2.imread(img_path)\n",
        "\n",
        "        # Resmi işleme (crop ve normalize)\n",
        "        processed_image = process_image(image)\n",
        "\n",
        "        # İşlenmiş resmi kaydet\n",
        "        output_filename = os.path.join(output_dir, f\"processed_{filename}\")\n",
        "        processed_image = (processed_image * 255).astype(np.uint8)  # [0, 1] -> [0, 255]\n",
        "        cv2.imwrite(output_filename, cv2.cvtColor(processed_image, cv2.COLOR_RGB2BGR))  # OpenCV BGR formatında\n",
        "\n",
        "        print(f\"{output_filename} başarıyla kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPfcH5RqlyBK",
        "outputId": "4ae6f721-37fa-414a-cbfb-b5973980360f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processed_images/processed_11.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_6.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_4.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_5.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_9.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_10.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_7.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_8.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_12.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_19.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_24.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_16.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_20.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_30.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_29.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_22.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_23.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_28.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_21.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_13.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_26.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_15.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_31.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_18.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_34.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_17.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_33.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_27.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_32.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_41.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_38.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_37.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_42.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_45.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_39.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_44.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_43.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_46.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_40.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_35.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_1.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_2.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_64.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_53.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_3.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_25.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_54.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_51.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_50.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_48.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_36.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_47.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_49.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_55.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_52.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_14.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_68.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_66.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_56.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_65.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_59.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_61.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_62.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_58.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_70.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_69.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_63.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_60.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_57.jpg başarıyla kaydedildi.\n",
            "processed_images/processed_67.jpg başarıyla kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "from torchvision import transforms\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, image_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(('jpg', 'png'))]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        image = cv2.imread(img_name)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # BGR -> RGB\n",
        "\n",
        "        # İşleme adımları\n",
        "        image = process_image(image)  # Önceden tanımlanan işlem fonksiyonlarıyla\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image\n",
        "\n",
        "# Resimleri işlemek için dönüşümler\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((256, 256)),\n",
        "])\n",
        "\n",
        "# Dataset ve DataLoader\n",
        "dataset_dir = \"processed_images\"\n",
        "dataset = CustomImageDataset(image_dir=dataset_dir, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "4Yg2bbXTLoeq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Denetimsiz Model Eğitimi"
      ],
      "metadata": {
        "id": "ZYNrcnmaimar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import cv2\n",
        "import os"
      ],
      "metadata": {
        "id": "zhwMDC8-l7XG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cqylunlun/GLASS.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSoyJGSKKO-9",
        "outputId": "2ff8d023-a752-4b55-9748-c001593a91a4"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'GLASS'...\n",
            "remote: Enumerating objects: 200, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (23/23), done.\u001b[K\n",
            "remote: Total 200 (delta 70), reused 61 (delta 59), pack-reused 118 (from 1)\u001b[K\n",
            "Receiving objects: 100% (200/200), 8.23 MiB | 17.92 MiB/s, done.\n",
            "Resolving deltas: 100% (108/108), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/GLASS')\n"
      ],
      "metadata": {
        "id": "UXT4cRnaKPED"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from glass import GLASS  # Reposu içerisindeki kodu import et\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Cihazı (GPU/CPU) seçin\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ResNet50 modelini yükle\n",
        "backbone_model = models.resnet50(pretrained=True)  # Önceden eğitilmiş ResNet50\n",
        "backbone_model = backbone_model.to(device)  # Modeli doğru cihaza (GPU/CPU) yükle\n",
        "\n",
        "# Modeli başlatma\n",
        "input_shape = (3, 224, 224)  # Giriş boyutu (3 renk kanalı, 224x224)\n",
        "target_embed_dimension = 128  # Hedef embed boyutu\n",
        "pretrain_embed_dimension = 512  # Önceden eğitimli embed boyutu\n",
        "\n",
        "# GLASS modelini başlat\n",
        "glass_model = GLASS(device)\n",
        "\n",
        "# GLASS modeline backbone olarak ResNet50 modelini yükle\n",
        "glass_model.load(\n",
        "    backbone=backbone_model,\n",
        "    layers_to_extract_from=[0, 1, 2],  # Hangi katmanlardan özellik çıkarılacağı\n",
        "    device=device,\n",
        "    input_shape=input_shape,\n",
        "    pretrain_embed_dimension=pretrain_embed_dimension,\n",
        "    target_embed_dimension=target_embed_dimension\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 480
        },
        "id": "bHZKjcOBKPG1",
        "outputId": "5f1cd189-f042-487a-cf56-3ddbd5d1f474"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:01<00:00, 86.6MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "argument of type 'int' is not iterable",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-d930d698f21e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# GLASS modeline backbone olarak ResNet50 modelini yükle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m glass_model.load(\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mbackbone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackbone_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mlayers_to_extract_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Hangi katmanlardan özellik çıkarılacağı\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLASS/glass.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, backbone, layers_to_extract_from, device, input_shape, pretrain_embed_dimension, target_embed_dimension, patchsize, patchstride, meta_epochs, eval_epochs, dsc_layers, dsc_hidden, dsc_margin, train_backbone, pre_proj, mining, noise, radius, p, lr, svd, step, limit, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_modules\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         feature_aggregator = common.NetworkFeatureAggregator(\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_to_extract_from\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_backbone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         )\n",
            "\u001b[0;32m/content/GLASS/common.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, backbone, layers_to_extract_from, device, train_backbone)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mextract_layer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers_to_extract_from\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLASS/common.py\u001b[0m in \u001b[0;36mregister_hook\u001b[0;34m(self, layer_name)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0mforward_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mForwardHook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers_to_extract_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/GLASS/common.py\u001b[0m in \u001b[0;36mfind_module\u001b[0;34m(self, model, module_name)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32melif\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0mfather\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mfather\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'int' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t612NHtMKPI7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}